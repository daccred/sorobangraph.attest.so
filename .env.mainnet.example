# .env.mainnet - Stellar Mainnet Configuration
# ==============================================
# Use this file for connecting to Stellar's public network
# Copy to .env to activate: cp .env.mainnet .env
#
# ⚠️  WARNING: This connects to the live Stellar network
# Ensure proper security measures and database backups

# Database Configuration
# ----------------------
# PostgreSQL connection string
# For production, use a secure password and consider SSL
DATABASE_URL="postgres://stellar"

# Network Configuration
# ---------------------
# Mainnet network settings
NETWORK_MODE=mainnet
NETWORK_PASSPHRASE=Public Global Stellar Network ; September 2015
HISTORY_ARCHIVE_URLS=https://history.stellar.org/prd/core-live/core_live_001

# Ingestion Configuration
# -----------------------
# Start from genesis (0) or specific ledger number
# Note: Mainnet has millions of ledgers, consider starting from a recent one
START_LEDGER=0
# End at specific ledger (0 = continuous streaming)
END_LEDGER=0

# API Configuration
# -----------------
# Enable WebSocket support for real-time updates
ENABLE_WEBSOCKET=true
# API server port (default: 8080)
PORT=8080

# Logging Configuration
# ---------------------
# Log level: debug, info, warn, error
# For production, consider using 'warn' or 'error'
LOG_LEVEL=info

# Captive Core Configuration (RECOMMENDED for Mainnet)
# -----------------------------------------------------
# Captive Core provides real-time ingestion without history archive delays
# Install stellar-core first: https://developers.stellar.org/docs/run-core-node
#
# Uncomment and configure the following:
# CAPTIVE_CORE_BINARY_PATH=/usr/bin/stellar-core
# CAPTIVE_CORE_CONFIG_PATH=/etc/stellar-core-mainnet.cfg

# Performance Tuning (Mainnet Specific)
# --------------------------------------
# Consider these settings for production:
# - Use connection pooling for PostgreSQL
# - Enable read replicas for API queries
# - Set up proper monitoring and alerting

# Filter Configuration (Optional)
# -------------------------------
# Comma-separated list of contract addresses to filter
# Only events from these contracts will be ingested
# This can significantly reduce storage requirements
# FILTER_CONTRACTS=CONTRACT_ID_1,CONTRACT_ID_2